{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basketball-Reference Game Log Data Scraper\n",
    "_To run any of the sections of code, click into the section, and press [Ctrl]+[Enter]_  \n",
    "__Note: In order for this code to function correctly, it must be executed chronologically, starting at the top__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install/Import required Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If necessary, install BeautifulSoup4 and Pandas Packages:\n",
    "!pip install BeautifulSoup4\n",
    "!pip install pandas\n",
    "!pip install tqdm\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First use Kernel [3] to import all of the required python libraries for this project.  \n",
    "***\n",
    "If any library does not load, uncomment (remove the # before) the associated '!pip install' command in Kernel [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import unicodedata\n",
    "import numpy\n",
    "from tqdm import tqdm\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the years/months that you want to pull game data from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the year you want to pull data from - only limited to single years for the time being.\n",
    "year = 2021\n",
    "\n",
    "#Comment out any months you DO NOT want game data pulled from:\n",
    "months = [\n",
    "'october', \n",
    "'november',\n",
    "'december',\n",
    "'january',\n",
    "#'february',\n",
    "#'march',\n",
    "#'april',\n",
    "#'may',\n",
    "#'june',\n",
    "#'july',\n",
    "#'august',\n",
    "#'september'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Link Creation Progress: 100%|████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Links successfully created for october, november, december, january of 2021.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "links = []\n",
    "links_tmp = []\n",
    "with tqdm(total=len(months),desc='Link Creation Progress') as pbar:\n",
    "    for month in range(len(months)):\n",
    "        url = 'https://www.basketball-reference.com/leagues/NBA_'+str(year)+'_games-'+months[month]+'.html'\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "        links_tmp = [game['href'] for game in soup.find_all('a', text='Box Score')]\n",
    "        base_url = \"https://www.basketball-reference.com\"\n",
    "        links_tmp = [base_url + link for link in links_tmp]\n",
    "        for link in links_tmp:\n",
    "            links.append(link)\n",
    "        pbar.update(1)\n",
    "\n",
    "print('Links successfully created for '+ ', '.join(months)+' of '+ str(year) + '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the Box Score Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Progress: 100%|█████████████████████████████████████████████████████████████| 100/100 [01:04<00:00,  1.54it/s]\n"
     ]
    }
   ],
   "source": [
    "stats = []\n",
    "with tqdm(total=len(links),desc='Scraping Progress') as pbar:\n",
    "    for link in range(len(links)):\n",
    "    #for link in range(150):\n",
    "        tmp = links[link]\n",
    "        page = requests.get(tmp)\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "        teams = [game['href'] for game in soup.find_all('a', {'itemprop': 'name'})]\n",
    "        teams = [teams[0][7:10], teams[1][7:10]]\n",
    "\n",
    "        stats_tmp = []\n",
    "        for team in range(len(teams)):\n",
    "            basic_stats = soup.find('table',{'id': 'box-'+teams[team]+'-game-basic'})\n",
    "            adv_stats = soup.find('table',{'id': 'box-'+teams[team]+'-game-advanced'})\n",
    "\n",
    "            #Player Names\n",
    "            player_names = [[th.getText() for th in basic_stats.findAll('tr')[1:][i].findAll('th')] for i in range(len(basic_stats.findAll('tr')[1:]))]\n",
    "            player_names = player_names[1:6] + player_names[7:-1]\n",
    "            df_player_names = pd.DataFrame(player_names)\n",
    "\n",
    "            #Starters\n",
    "            starters = ['Y','Y','Y','Y','Y'] + ['N']*(len(player_names)-5)\n",
    "            df_starters = pd.DataFrame(starters)\n",
    "            \n",
    "            #Player Basic Stats\n",
    "            team_stats_basic = [[td.getText() for td in basic_stats.findAll('tr')[1:][i].findAll('td')]\n",
    "                    for i in range(len(basic_stats.findAll('tr')[1:]))]\n",
    "            team_stats_basic = team_stats_basic[1:6] + team_stats_basic[7:-1]\n",
    "            df_team_stats_basic = pd.DataFrame(team_stats_basic)\n",
    "\n",
    "            #Player Advanced Stats\n",
    "            team_stats_adv = [[td.getText() for td in adv_stats.findAll('tr')[1:][i].findAll('td')]\n",
    "                    for i in range(len(adv_stats.findAll('tr')[1:]))]\n",
    "            team_stats_adv = team_stats_adv[1:6] + team_stats_adv[7:-1]\n",
    "            df_team_stats_adv = pd.DataFrame(team_stats_adv)\n",
    "\n",
    "            #Game ID\n",
    "            game_id = links[link][47:59]\n",
    "            game_id = [game_id for i in range(len(player_names))]\n",
    "            df_game_id = pd.DataFrame(game_id)\n",
    "\n",
    "            #Team ID\n",
    "            team_name = [teams[team] for i in range(len(player_names))]\n",
    "            df_team_name = pd.DataFrame(team_name)\n",
    "\n",
    "            #Consolidating the Data:\n",
    "            stats_tmp = pd.concat([df_game_id,df_team_name,df_player_names,df_starters,df_team_stats_basic,df_team_stats_adv],axis=1)\n",
    "            stats.append(stats_tmp)\n",
    "        pbar.update(1)\n",
    "    \n",
    "    output_raw = pd.concat(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Post-Processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output_raw\n",
    "#Add a header to the Data\n",
    "header = ['Game_ID','Team','Player','Starter','Min','FG','FGA','FG%','3P','3PA','3P%','FT','FTA','FT%','ORB','DRB','TRB','AST','STL','BLK','TOV','PF','PTS','P/M',\n",
    "          'del','TS%','eFG%','3PAr', 'FTr','ORB%','DRB%','TRB%','AST%','STL%','BLK%','TOV%','USG%','ORtg','DRtg','BPM']\n",
    "output.columns = header\n",
    "\n",
    "#Index Column - Reset IDs\n",
    "output = output.reset_index(drop=True)\n",
    "\n",
    "#Player Column - Replace any special characters with the 26 basic alphabetic characters.\n",
    "output['Player'] = output['Player'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "\n",
    "#MP - Convert to decimal\n",
    "for row in range(len(output['Min'])):\n",
    "    if \":\" in output['Min'][row]:\n",
    "        output['Min'][row] = round(float(output['Min'][row].split(':')[0]+str(int(output['Min'][row].split(':')[1])/60)[1:]),2)\n",
    "    else:\n",
    "        output['Min'][row] = 0\n",
    "\n",
    "#Delete redundant Minutes Played (del) column:\n",
    "output = output.drop(['del'],axis=1)\n",
    "\n",
    "#Convert statistical columns to float type in order to calculate fantasy points\n",
    "output['PTS'] = pd.to_numeric(output['PTS'],downcast='float')\n",
    "output['3P'] = pd.to_numeric(output['3P'],downcast='float')\n",
    "output['TRB'] = pd.to_numeric(output['TRB'],downcast='float')\n",
    "output['AST'] = pd.to_numeric(output['AST'],downcast='float')\n",
    "output['STL'] = pd.to_numeric(output['STL'],downcast='float')\n",
    "output['BLK'] = pd.to_numeric(output['BLK'],downcast='float')\n",
    "output['TOV'] = pd.to_numeric(output['TOV'],downcast='float')\n",
    "\n",
    "#Dealing with Double Doubles/Triple Doubles \n",
    "isTen = lambda x:int(x>=10)\n",
    "countTens = lambda row: numpy.clip(isTen(row['PTS']) + isTen(row['TRB']) + isTen(row['AST']) + isTen(row['STL']) + isTen(row['BLK']),1,3)-1\n",
    "output['DDBonus'] = output.apply(countTens,axis=1)\n",
    "\n",
    "#Calculating Fantasy Points\n",
    "output['Fp'] = 1*output['PTS'] + 0.5*output['3P'] + 1.25*output['TRB'] + 1.5*output['AST'] + 2*output['STL'] + 2*output['BLK'] - 0.5*output['TOV'] + 1.5*output['DDBonus']\n",
    "\n",
    "#Calculating Fantasy Points per Minute\n",
    "FpMin = []\n",
    "for row in range(len(output['Min'])):\n",
    "    if output['Min'][row] == 0:\n",
    "        FpMin.append(0)\n",
    "    else:\n",
    "        FpMin.append(round(output['Fp'][row] / output['Min'][row],3))\n",
    "output['Fp/Min'] = FpMin\n",
    "        \n",
    "#Replace any blank cells with 0\n",
    "output = output.fillna(0)\n",
    "output = output.replace('',0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If preferred, run the kernel below to create a temporary .csv file in Binder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('2020stats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoexport to Google Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gspread\n",
    "#!pip install gspread_dataframe\n",
    "import gspread\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "\n",
    "gc = gspread.oauth()\n",
    "sh = gc.open_by_key('1ZmvBC3wiXHROO-I2aovyW2zF9t_z-gan4oDqRP0wSHE')\n",
    "worksheet = sh.get_worksheet(0)\n",
    "\n",
    "range_of_cells = worksheet.range('A1:AN50000') #-> Select the range you want to clear\n",
    "for cell in range_of_cells:\n",
    "    cell.value = ''\n",
    "set_with_dataframe(worksheet, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
